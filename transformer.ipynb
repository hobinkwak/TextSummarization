{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"practice_03_transformer.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyM5sqq550sdzzqlPgPB1fwR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFxOS5LYeq6n","executionInfo":{"status":"ok","timestamp":1623079505866,"user_tz":-540,"elapsed":20785,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}},"outputId":"f4e69c22-aba6-4519-837f-58a50d5dc5ff"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/') \n","os.chdir('/content/gdrive/My Drive/Colab Notebooks/챗봇')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWjNZYxGewFV","executionInfo":{"status":"ok","timestamp":1623079512836,"user_tz":-540,"elapsed":6976,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}},"outputId":"2139dbc3-7577-48d9-a6bb-02a554179286"},"source":["!pip install konlpy"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 282kB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n","\u001b[K     |████████████████████████████████| 460kB 37.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.8MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ijS3WEjTex-I","executionInfo":{"status":"ok","timestamp":1623079538276,"user_tz":-540,"elapsed":3587,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","from konlpy.tag import Okt\n","import pandas as pd\n","import tensorflow as tf\n","import enum\n","import os\n","import re\n","import json\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","\n","from preprocess import *"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"57NJgPAtfTh-","executionInfo":{"status":"ok","timestamp":1623079540248,"user_tz":-540,"elapsed":270,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}}},"source":["def plot_graphs(history, string):\n","    plt.plot(history.history[string])\n","    plt.plot(history.history['val_'+string], '')\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(string)\n","    plt.legend([string, 'val_'+string])\n","    plt.show()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_4MQj4jgK2n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623079619775,"user_tz":-540,"elapsed":28896,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}},"outputId":"41246b69-2516-437d-a707-a870f8c899ee"},"source":["PATH = 'data_in/ChatBotData.csv'\n","VOCAB_PATH = 'data_in/vocabulary.txt'\n","\n","inputs, outputs = load_data(PATH)\n","char2idx, idx2char, vocab_size = load_vocabulary(PATH, VOCAB_PATH, tokenize_as_morph=True, method='Okt')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/11823 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Okt\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 11823/11823 [00:14<00:00, 801.44it/s]\n","100%|██████████| 11823/11823 [00:13<00:00, 859.48it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ia-xe1xgYDj","executionInfo":{"status":"ok","timestamp":1623079660392,"user_tz":-540,"elapsed":37983,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}},"outputId":"db5ee704-1cbf-46f6-a8dd-381487237182"},"source":["index_inputs, input_seq_len = enc_processing(inputs, char2idx, tokenize_as_morph=True, method='Okt')\n","index_outputs, output_seq_len = dec_output_processing(outputs, char2idx, tokenize_as_morph=True, method='Okt')\n","index_targets = dec_target_processing(outputs, char2idx, tokenize_as_morph=True, method='Okt')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["  2%|▏         | 210/11823 [00:00<00:05, 2099.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Okt\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 11823/11823 [00:10<00:00, 1127.34it/s]\n","  1%|▏         | 156/11823 [00:00<00:07, 1545.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["Okt\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 11823/11823 [00:13<00:00, 884.16it/s]\n","  0%|          | 0/11823 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Okt\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 11823/11823 [00:13<00:00, 868.55it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"yA6BiSu_IEDL"},"source":["> ** Okt 문장그대로 **"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CqjcEk_QE9yR","executionInfo":{"status":"ok","timestamp":1623079754073,"user_tz":-540,"elapsed":262,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}},"outputId":"bb3d8e02-4f34-4a8f-f61e-181683c877b8"},"source":["vocab_size"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12657"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"zd0NoEuAgYN7","executionInfo":{"status":"ok","timestamp":1623079767009,"user_tz":-540,"elapsed":1262,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}}},"source":["data_configs = {}\n","data_configs['char2idx'] = char2idx\n","data_configs['idx2char'] = idx2char\n","data_configs['vocab_size'] = vocab_size\n","data_configs['pad_symbol'] = PAD\n","data_configs['std_symbol'] = STD\n","data_configs['end_symbol'] = END\n","data_configs['unk_symbol'] = UNK\n","\n","DATA_IN_PATH = './data_in/'\n","DATA_OUT_PATH = './data_out/'\n","TRAIN_INPUTS = 'train_inputs.npy'\n","TRAIN_OUTPUTS = 'train_outputs.npy'\n","TRAIN_TARGETS = 'train_targets.npy'\n","DATA_CONFIGS = 'data_configs.json'\n","\n","np.save(open(DATA_IN_PATH + TRAIN_INPUTS, 'wb'), index_inputs)\n","np.save(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'wb'), index_outputs)\n","np.save(open(DATA_IN_PATH + TRAIN_TARGETS , 'wb'), index_targets)\n","\n","json.dump(data_configs, open(DATA_IN_PATH + DATA_CONFIGS, 'w'))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKzTj22FgYVq","executionInfo":{"status":"ok","timestamp":1623079775613,"user_tz":-540,"elapsed":397,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}}},"source":["index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n","index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n","index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n","prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hY5eIc-gYcO","executionInfo":{"status":"ok","timestamp":1623079776615,"user_tz":-540,"elapsed":4,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}}},"source":["char2idx = prepro_configs['char2idx']\n","end_index = prepro_configs['end_symbol']\n","model_name = 'transformer'\n","vocab_size = prepro_configs['vocab_size']\n","BATCH_SIZE = 2\n","MAX_SEQUENCE = 25\n","EPOCHS = 30\n","VALID_SPLIT = 0.1\n","\n","kargs = {\n","         'num_layers': 2,\n","         'd_model': 512,\n","         'num_heads': 8,\n","         'dff': 2048,\n","         'input_vocab_size': vocab_size,\n","         'target_vocab_size': vocab_size,\n","         'maximum_position_encoding': MAX_SEQUENCE,\n","         'end_token_idx': char2idx[end_index],\n","         'rate': 0.1\n","        }"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A6HiUbQi1p7j"},"source":["# 패딩 및 포워드 마스킹"]},{"cell_type":"code","metadata":{"id":"opuEgIwA1sLk","executionInfo":{"status":"ok","timestamp":1623081704791,"user_tz":-540,"elapsed":289,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}}},"source":["def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","\n","    # add extra dimensions to add the padding\n","    # to the attention logits.\n","    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"25hpK0KNj85n"},"source":["# 순방향 마스크 어텐션"]},{"cell_type":"code","metadata":{"id":"9hcigGpMjC-X"},"source":["def create_look_ahead_mask(size):\n","  mask = 1- tf.linalg.band_part(input=tf.ones((size,size)), num_lower=-1, num_upper=0)\n","  return mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlWHmnqCgYpS"},"source":["def scaled_dot_product_attention(q,k,v,mask):\n","  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (batch, seq_len_q, seq_len_k)\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(df)\n","\n","  if mask is not None:\n","    scaled_attention_logits += (mask * -1e9)\n","  \n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # (batch, seq_len_q, seq_len_k)\n","  output = tf.matmul(attention_weights, v)  # # (batch, seq_len_q, depth_v)\n","  return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZAAt3Na2iJzR"},"source":["# 멀티헤드 어텐션"]},{"cell_type":"code","metadata":{"id":"sKzl0RsMiKDb"},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, **kargs):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = kargs['num_heads']\n","    self.d_model = kargs['d_model']\n","\n","    assert self.d_model % self.num_heads == 0\n","\n","    self.depth = self.d_model // self.num_heads\n","\n","    # 스케일 내적 연산 이전에 입력한 key, query, value에 대한 차원수를 맞추기 위한 레이어\n","    self.wq = tf.keras.layers.Dense(kargs['d_model'])\n","    self.wk = tf.keras.layers.Dense(kargs['d_model'])\n","    self.wv = tf.keras.layers.Dense(kargs['d_model'])\n","\n","    # 셀프 어텐션 레이어를 출력하기 위한 레이어다. \n","    self.dense = tf.keras.layers.Dense(kargs['d_model'])\n","\n","  # 이번에는 각 벡터를 헤드 수만큼 나눌 수 있게 한다.\n","  # key, query, value에 대한 벡터를 헤드 수만큼 분리할 수 있게 하는 함수\n","  # [batch, sequence, feature] -> [batch, head, sequence, feature]\n","  def split_heads(self, x, batch_size):\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0,2,1,3])\n","\n","  def call(self, v, k, q, mask):\n","    batch_size = tf.shape(q)[0]\n","\n","    q = self.wq(q)  #(batch, sequnce, d_model)\n","    k = self.wk(k)  #(batch, sequnce, d_model)\n","    v = self.wv(v)  #(batch, sequnce, d_model)\n","\n","    q = self.split_heads(q, batch_size)  # (batch, num_heads, seq, depth)\n","    k = self.split_heads(k, batch_size)\n","    v = self.split_heads(v, batch_size)\n","\n","    #scaled_attention.shape == (batch, num, seq_len_q, depth)    \n","    #attention_weights.shape == (batch, num, seq_len_q, seq_len_k)\n","    scaled_attention, attention_weights = scaled_dot_product_attention(q,k,v,mask)\n","\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0,2,1,3])\n","    #(batch, seq_len_q, num, depth)\n","    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","    # (batch, seq_len_q, d_model)\n","    output = self.dense(concat_attention) # (batch, seq_len_q, d_model)\n","\n","    return output, attention_weights\n","\n","\n","\n","\n","  \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELTHl20xiKLz"},"source":["# 포인트 와이즈 피드포워드 네트워크\n","\n","$ FFN(x) = max(0, xW_1 + b_1)W_2 + b_2 $"]},{"cell_type":"markdown","metadata":{"id":"ag2vnYKeiKTs"},"source":["- 한 문장 안에 있는 단어 토큰 벡터 각각에 대해 연산하는 네트워크\n","- 두 개의 linear 레이어를 거치고 그 사이 활성화 함수로 ReLU를 활용."]},{"cell_type":"code","metadata":{"id":"1xIhOKjOkiis"},"source":["def point_wise_feed_forward_network(**kargs):\n","  return tf.keras.Sequential([\n","                              tf.keras.layers.Dense(kargs['dff'], activation='relu'),\n","                              tf.keras.layers.Dense(kargs['d_model'])])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5A6c-R3ki0S"},"source":["# Residual Connection"]},{"cell_type":"markdown","metadata":{"id":"U_52k3sOki8j"},"source":["```python\n","self.ffn = point_wise_feed_forward_network(d_model, dff)\n","self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","ffn_output = self.ffn(out1)\n","out2 = self.layernorm2(out1 + ffn_output)\n","```"]},{"cell_type":"markdown","metadata":{"id":"5iA6j2YxqVlK"},"source":["- 인코더 레이어에서 리지듀얼 커넥션을 수행하는 부분을 보여준다.\n","- 먼저 연산할 레이어 피드 포워드 네트워크와 레이어 노멀라이즈를 각각 생성한다.\n","- 레이어 노멀라이즈는 각 레이어별 뉴런을 노멀라이즈하는 역할이라고 이해하면 된다.\n","- 피드 포워드 네트워크를 만들기 위해서는 앞서 구현한 point_wise_feed_forward_network를 통해 네트워크를 생성한다.\n","\n","> - 입력 벡터 out1을 먼저 self.ffn을 통해 피드 포워드 연산을 하게 해서 ffn_outpu으로 할당한다. 그 다음 입력 벡터 out1과 피드 포워드 네트워크를 거쳐 나온 ffn_output을 더해 리지듀얼 커넥션을 수행한다.\n","\n","\n","> - 이게 transformer모델에서 **Add&Norm**에 해당"]},{"cell_type":"markdown","metadata":{"id":"bKQlWXfKqV-Y"},"source":["# 포지션 인코딩"]},{"cell_type":"markdown","metadata":{"id":"6OyT9lQVqWGw"},"source":["- 트랜스포머는 seq2seq와 달리 단어 하나하나 순차적으로 넣지 않고 한번에 넣음. \n","- 따라서 입력 시퀀스 정보에 대한 순서 정보를 부가적으로 주입해야 함\n","- 여러 방법이 있으나 논문방법은\n","\n","$$ PE_{(pos,2i)} = sin(pos/10000^{{2i}/d_{model}}) $$\n","\n","$$ PE_{(pos,2i+1)} = cos(pos/10000^{{2i}/d_{model}}) $$"]},{"cell_type":"markdown","metadata":{"id":"onlmZcyPqWLJ"},"source":["- 첫번째 수식은 피처 차원에서 인덱스가 짝수인 경우에 대해 사인 함수값 할당\n","- 두번째는 피처 차원에서 인덱스가 홀수인 경우에 코사인 값 할당\n","- 함수 안에 있는 식은 각 시퀀스 위치에 따라 피처 차원 인덱스에 각자 위치 정보를 달리 주고자 하는 의도\n"]},{"cell_type":"code","metadata":{"id":"4Sma1MKuqWOh"},"source":["# pos/10000^(2i/dim) 에 해당\n","# pos는 포지션에 대한 인덱스 위치 리스트\n","# i에는 차원에 대한 리스트\n","# 각 순서에 따른 각도값을 얻는다.\n","\n","def get_angles(pos, i, d_model):\n","  angle_rates= 1/np.power(10000, (2*i) / np.float32(d_model))\n","  return pos * angle_rates"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bx05LxSpu-Vz"},"source":["def positional_encoding(position, d_model):\n","  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model)\n","  angle_rads[:, 0::2] = np.sin(angle_rads[:,0::2])\n","  angle_rads[:, 1::2] = np.cos(angle_rads[:,1::2])\n","\n","  pos_encoding = angle_rads[np.newaxis, ...]\n","\n","  return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pcFu0D7eqWRu"},"source":["# Encoder Layer"]},{"cell_type":"code","metadata":{"id":"AZ5cIz-wqWUy"},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, **kargs):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadAttention(**kargs)\n","    self.ffn = point_wise_feed_forward_network(**kargs)\n","\n","    self.layersnorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layersnorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","    self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n","    self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n","\n","  def call(self, x, mask):\n","    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(x + attn_output)\n","\n","    ffn_output = self.ffn(out1) # (batch_size, input_seq_len, d_model)\n","    ffn_output = self.dropout2(ffn_output)\n","    out2 = self.layernorm2(out1 + ffn_output) #(batch, input_seq_len, d_model)\n","\n","    return out2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WbCgjv-DkjBS"},"source":["# Encoder"]},{"cell_type":"code","metadata":{"id":"2BJHcfC5kjFM"},"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, **kargs):\n","    super(Encoder, self).__init__()\n","\n","    self.d_model = kargs['d_model']\n","    self.num_layers = kargs['num_layers']\n","\n","    self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)    \n","    self.pos_encdoing = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n","\n","    self.enc_layers = [EncoderLayer(**kargs) for _ in range(self.num_layers)]\n","\n","    self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n","\n","  def call(self, x, mask):\n","\n","    seq_len = tf.shape(x)[1]\n","\n","    x = self.embedding(x)\n","\n","    # 임베딩이 할당된 후에 임베딩 차원수의 제곱근만큼에 대한 가중치 곱함\n","    # 각 워드 임베딩에 대해 스케일을 맞추기 위함\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, mask)\n","\n","    return x #batch, input_seq_len, d_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-ZaRAf_kjJ6"},"source":["# Decoder 레이어"]},{"cell_type":"code","metadata":{"id":"fue7fK_DiKbU"},"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(**kargs)\n","        self.mha2 = MultiHeadAttention(**kargs)\n","\n","        self.ffn = point_wise_feed_forward_network(**kargs)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n","        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n","        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n","    \n","    \n","    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n","        # enc_output.shape == (batch_size, input_seq_len, d_model)\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n","        attn1 = self.dropout1(attn1)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        attn2, attn_weights_block2 = self.mha2(\n","            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n","        attn2 = self.dropout2(attn2)\n","        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n","        ffn_output = self.dropout3(ffn_output)\n","        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n","\n","        return out3, attn_weights_block1, attn_weights_block2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Evw8m1s118VL"},"source":["# Decoder"]},{"cell_type":"code","metadata":{"id":"jcWm2tcMgUvx"},"source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, **kargs):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = kargs['d_model']\n","        self.num_layers = kargs['num_layers']\n","\n","        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model)\n","        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n","\n","        self.dec_layers = [DecoderLayer(**kargs) \n","                           for _ in range(self.num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n","\n","    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","\n","        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x)\n","\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n","\n","            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","\n","        # x.shape == (batch_size, target_seq_len, d_model)\n","        return x, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OnXobvlqfYIK"},"source":["# Transformer"]},{"cell_type":"code","metadata":{"id":"PX3lFHMhfYLU"},"source":["class Transformer(tf.keras.Model):\n","    def __init__(self, **kargs):\n","        super(Transformer, self).__init__()\n","        self.end_token_idx = kargs['end_token_idx']\n","        \n","        self.encoder = Encoder(**kargs)\n","        self.decoder = Decoder(**kargs)\n","\n","        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n","\n","    def call(self, x):\n","        inp, tar = x\n","\n","        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n","        enc_output = self.encoder(inp, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","\n","        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","        dec_output, _ = self.decoder(\n","            tar, enc_output, look_ahead_mask, dec_padding_mask)\n","\n","        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","\n","        return final_output\n","    \n","    def inference(self, x):\n","        inp = x\n","        tar = tf.expand_dims([STD_INDEX], 0)\n","\n","        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)        \n","        enc_output = self.encoder(inp, enc_padding_mask)\n","        \n","        predict_tokens = list()\n","        for t in range(0, MAX_SEQUENCE):\n","            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n","            final_output = self.final_layer(dec_output)\n","            outputs = tf.argmax(final_output, -1).numpy()\n","            pred_token = outputs[0][-1]\n","            if pred_token == self.end_token_idx:\n","                break\n","            predict_tokens.append(pred_token)\n","            tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n","            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n","            \n","        return predict_tokens"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DO7n7JGzfYOi"},"source":["# 모델 로스 정의"]},{"cell_type":"code","metadata":{"id":"Pwz0wuaYfYRj"},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n","\n","def loss(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)\n","\n","def accuracy(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n","    pred *= mask    \n","    acc = train_accuracy(real, pred)\n","\n","    return tf.reduce_mean(acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja47o-fCfYUa"},"source":["model = Transformer(**kargs)\n","model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n","              loss=loss,\n","              metrics=[accuracy])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P30pVS9bfYXT","executionInfo":{"status":"ok","timestamp":1622878791482,"user_tz":-540,"elapsed":638,"user":{"displayName":"호빈","photoUrl":"","userId":"14158566037343033284"}},"outputId":"47563b4d-b300-49f4-dd56-966960237b8d"},"source":["# overfitting을 막기 위한 ealrystop 추가\n","earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n","# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n","# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n","\n","checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create path if exists\n","if os.path.exists(checkpoint_dir):\n","    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","else:\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","    \n","\n","cp_callback = ModelCheckpoint(\n","    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./data_out/transformer -- Folder already exists \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rrtQHLzCfUGA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J5twd0D21uay"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H37obOB7NeS9"},"source":[""],"execution_count":null,"outputs":[]}]}